{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bf934a-f9fc-46ae-9fbf-9de99c44e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd4ed22-007c-4637-ae4b-6d01e6506b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.6638e-02, -1.7067e-01,  7.6038e-03,  ...,  2.3386e-02,\n",
      "           1.0138e-01, -4.2516e-02],\n",
      "         [ 6.8078e-02, -1.5394e-01, -1.2517e-01,  ..., -1.1160e-02,\n",
      "           1.1047e-02, -1.3179e-03],\n",
      "         [ 1.5145e-02, -3.7817e-01, -1.0184e-01,  ..., -8.7419e-02,\n",
      "           1.0200e-01,  7.7285e-02],\n",
      "         ...,\n",
      "         [ 1.0243e-01, -3.4813e-01, -8.4518e-02,  ..., -1.1049e-01,\n",
      "           8.5594e-02, -4.6411e-02],\n",
      "         [-2.5399e-02,  7.7970e-03, -4.4150e-02,  ...,  9.5833e-02,\n",
      "          -6.1752e-02, -6.1012e-03],\n",
      "         [ 1.1801e-01, -1.2156e-01,  2.4940e-02,  ..., -9.5819e-03,\n",
      "           1.4038e-01, -3.2524e-02]],\n",
      "\n",
      "        [[ 1.2760e-01,  2.1539e-02, -4.1318e-02,  ..., -1.0661e-01,\n",
      "          -1.9259e-01, -5.4022e-03],\n",
      "         [ 1.4989e-01, -7.3531e-03, -9.6599e-02,  ..., -8.0247e-02,\n",
      "          -3.2525e-01, -1.0313e-04],\n",
      "         [ 2.1020e-01,  7.2041e-02, -3.7893e-02,  ...,  3.0247e-02,\n",
      "          -3.0968e-01,  1.3309e-02],\n",
      "         ...,\n",
      "         [ 9.5321e-02,  2.8475e-02, -4.2991e-03,  ..., -1.0701e-01,\n",
      "          -6.1208e-02,  1.5411e-02],\n",
      "         [ 1.2539e-01,  3.0186e-02, -3.1345e-02,  ..., -1.0506e-01,\n",
      "          -1.5439e-01, -4.9187e-02],\n",
      "         [ 1.1011e-01,  1.6679e-01, -8.9297e-02,  ..., -9.9172e-02,\n",
      "          -2.4063e-01, -3.6911e-02]]]) None\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0225, -0.0783, -0.0230,  ..., -0.0083,  0.0265, -0.0020],\n",
      "        [ 0.0417,  0.0011, -0.0155,  ..., -0.0218, -0.0636, -0.0088]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "print(model_output[0], model_output.hidden_states)\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5c5936-a250-41da-a884-c09a3658ec8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b8aaf-b7eb-42fb-aa58-3236ac0799d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3d0103-a573-44c1-acaa-73c3f6fa3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "\n",
    "def get_hidden_states(encoded, token_ids_word, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "       Select only those subword token outputs that belong to our word of interest\n",
    "       and average them.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "\n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "    # Only select the tokens that constitute the requested word\n",
    "    word_tokens_output = output[token_ids_word]\n",
    "\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n",
    "\n",
    "def get_word_vector(sent, idx, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "       that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    "\n",
    "    return get_hidden_states(encoded, token_ids_word, model, layers)\n",
    "\n",
    "\n",
    "def main(sent=\"I like cookies .\", word=\"cookies\", layers=None):\n",
    "    # Use last four layers by default\n",
    "    layers = [-4, -3, -2, -1] if layers is None else layers\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\", output_hidden_states=True)\n",
    "\n",
    "    idx = get_word_idx(sent, word)\n",
    "\n",
    "    word_embedding = get_word_vector(sent, idx, tokenizer, model, layers)\n",
    "    \n",
    "    return word_embedding \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf48e82-4617-4cd4-aff3-8960ce75b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank1 = main(\"She sat on the river bank across from a series of wide, large steps leading up a hill to the park where the Arch stood, framed against a black sky.\", \"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6ed3bb-ef6d-40fd-bd7a-ab2fa218653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "river = main(\"He swam across the river Thames.\", \"river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9190e42-6aa3-428a-b1cd-51b94897b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    assert a.ndim == b.ndim\n",
    "    if a.ndim == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "        b = b.unsqueeze(0)\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    res = a_norm @ b_norm.transpose(0,1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a19bb4-25b4-4af7-839d-4c06e61d2f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3417)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank1@river/bank1.norm()/river.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad678f12-46a4-483a-9fa2-bd87e6cf62f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3417]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(bank1, river)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad67186e-4545-430c-b083-3c578b145170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "river.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "814c14b7-6e54-43d6-8fe0-12a9d2a8f735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69602a3dab564267923b11e1b5adff11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38a0c9f83364540883e42fc4d0073b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0f05f5fa18445fb20649bddea0123d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accd6b64e31945bb89ac212a1cb6bb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52993b2ed774ba1b38b2d8a6ce522ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6658e0858746b9a6932bacbaca85ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a00feb743246d98ef9e5a5efff5df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd833b820c3c443db4a34a2a1811d7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7750c37abb4f34b64be174d5d4a24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb5090bf5c04acdb885b4413434afc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a348104a424b92b7bd060c120fb3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b490416ed5394329895c6ddd54080bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe9b5ce883a41568eae81c1c9ccdf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3669ede054c442168840ced64b03784a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"fall\", \"iron\", \"witch\", \"ham\", \"note\", \"cat\", \"beijing\", \"bear\", \"ambulance\"]\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfa48274-4db7-4d4a-8f55-f4b0de405f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similarity(word, corpus_embeddings):\n",
    "    query_embeddings = torch.tensor(model.encode(word))\n",
    "    query_embeddings /= query_embeddings.norm()\n",
    "    corpus_embeddings = torch.tensor(corpus_embeddings)\n",
    "    corpus_embeddings = corpus_embeddings/corpus_embeddings.norm(dim=1)[:, None]\n",
    "    return corpus_embeddings @ query_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e00b40-fa65-4bb8-9ee9-5a2162bc1a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1688, 0.3186, 0.3222, 0.3003, 0.3719, 0.2479, 0.2199, 0.2653, 0.2037])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_similarity(\"wok\", corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f5937d7-6871-44c1-8d2a-b164416d2af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164cfe4e63c6474f89c8b4f9671380e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8e3b3f775f4d8f9362c4a3d119b122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d19fa5b74441f598e1f46b64c26cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/540 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9828e1d3633c43cdbd6371750f97f038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c1679638c541aa9d408aca1a44f00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6470b7c1c4e14ea1998ce42f0f450718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a016249c6246c187eda34819c8015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495a2b705af3446c990d24e765fe2fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db350a4e90c24cd1927953e0a116a7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc34980933ea460185b2bc03cc27f998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/554 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a38691ab42488a8a4985b7c85747c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de1df3403954d31a0a1d4654550b98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.6503]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('nq-distilbert-base-v1')\n",
    "\n",
    "query_embedding = model.encode('How many people live in London?')\n",
    "\n",
    "#The passages are encoded as [ [title1, text1], [title2, text2], ...]\n",
    "passage_embedding = model.encode([['London', 'London has 9,787,426 inhabitants at the 2011 census.']])\n",
    "\n",
    "print(\"Similarity:\", util.pytorch_cos_sim(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af7be3-0ac2-4ee3-b56d-a2531e19f3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (fn_env)",
   "language": "python",
   "name": "fn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
